---
title: StyleGAN Paper Review
tags:
  - Deep Learning
  - Paper
  - GAN
---
A brief paper review of StyleGAN <br>
<!--more-->

---
### StyleGAN
[StyleGAN](https://github.com/NVlabs/stylegan)은 이미지의 스타일을 바꿔주는 생성 모델로 2018년 NVidia에서 발표했다. <br>

#### Introduction

StyleGAN은 기존 GAN(Generative Adversarial Network)를 기반으로 한 이미지 생성 모델들이 이미지 생성, 합성 과정은 block box이고, 합성 과정에서 atrribute를 조절하기 힘들고 artifact들이 나타나는 현상을 해결하기 위해 제시되었다. <br> StyleGAN은 input space(input image)를 그대로 GAN 모델에 넣는 것이 아닌 latent space로 mapping 하여 model에 input으로 넣었다. Input image의 probability density를 따르는 latent space는 input space의 entanglement를 어느정도 해결하여 image attribute 조절에 도움이 된다.<br>

#### Style-based generator

![StyleGAN_Image1](https://user-images.githubusercontent.com/48177363/143530735-8c468fc7-6c96-4547-b94e-fbfd5f9497c1.jpg){: width="600"} <br>

전통적인 GAN은 latent space $$\mathcal{Z}$$(input image)를 그래도 GAN network의 첫번째 layer의 input으로 넣는 방식이 많았다. 하지만 StyleGAN에서는 $$\mathcal{Z}$$를 이미지 스타일 생성을 위한 latent space $$\mathcal{W}$$로 mapping 시킨 후 AdaIN을 사용하여 image에 style을 입힌다. 
<details>
  <summary>
    AdaIN
  </summary>  
  AdaIN은 Content의 평균, 분산을 통해 스타일을 일치시키는 방식이다. 보통 style transfar는 이미지 등의 probability distribution를 일치시킴으로서 일어난다.<br>
  <ul>
    <li>Batch Normalization </li> <br>
  Batch Normalization은 feature map을 channel 별로 mean과 std를 정규화시키는 방식이다. Network에 input이 minibatch 단위로 들어갈 때, batch의 각 channel을 같이 normalization 시킨다. <br>
    <ul>
      <li>$$BN(x) = \gamma (\frac{x - \mu (x)}{\sigma (x)}) + \beta$$ ($$\gamma, \beta$$는 parameter 다)</li>
      <li>$$\mu_{c}(x) = \frac{1}{NHW}\sum^{N}_{1}\sum^{H}_{1}\sum^{W}_{1}x_{nchw}$$</li>
      <li>$$\sigma_{c}(x) = \sqrt{\frac{1}{NHW}\sum^{N}_{1}\sum^{H}_{1}\sum^{W}_{1}(x_{nchw}-\mu_{c}(x))^{2}+\epsilon}$$</li>
    </ul>
  <li>Instance Normalization</li><br>
  Batch Normalization이 같은 위치의 channel이면 batch 단위로 normalization을 진행했던 것과 다르게 IN은 각 sample 마다 channel 별로 normalization을 진행한다. <br>
    <ul>
      <li>$$IN(x) = \gamma (\frac{x - \mu (x)}{\sigma (x)}) + \beta$$ ($$\gamma, \beta$$는 parameter 다)</li>
      <li>$$\mu_{nc}(x) = \frac{1}{HW}\sum^{H}_{1}\sum^{W}_{1}x_{nchw}$$</li>
      <li>$$\sigma_{nc}(x) = \sqrt{\frac{1}{HW}\sum^{H}_{1}\sum^{W}_{1}(x_{nchw}-\mu_{nc}(x))^{2}+\epsilon}$$</li>
    </ul>
  
</details>
