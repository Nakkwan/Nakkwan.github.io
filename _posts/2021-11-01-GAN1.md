---
title: GAN 1
tags:
  - Deep Learning
  - Paper
  - GAN
---
A brief note on GANs <br>
vanilla GAN, Conditional GAN, Pix2Pix, PatchGAN, StarGAN, PGGAN
<!--more-->

---
### vanilla GAN
<br>
GAN = Generative Adversarial Network <br>
GAN은 진짜 모델과 비슷한 가짜 모델을 만드는 적대적 생성 네트워크로 unsupervised training에 속한다.<br>
latent variable z로부터 가짜 데이터를 생성하는 Generator G와 G로부터 생성한 가짜 데이터와 진짜 데이터를 구별하는 Discriminator D가 존재한다. 
G는 D를 속일 수 있도록 학습되고 D는 진짜 데이터를 판별할 수 있도록 학습되며 G와 D가 경쟁하여 학습된다. <br>

![GAN1_Image1](https://user-images.githubusercontent.com/48177363/140280172-dfe2449f-0e34-4ab5-88f4-b4a47b05ee67.jpg){: width="750"} <br>

Loss: $$\min_{G}\max_{D}V(D,G) = \mathbb{E}_{x~p_{data}(x)}[\log (D(x))] + \mathbb{E}_{z~p_{z}(z)}[\log (1-D(G(z)))]$$<br>
- G: $$\nabla_{\theta_{g}}\frac{1}{m}\sum_{i=1}^{m}\log (1-D(G(z^{(i)})))$$ <br>
- D: $$\nabla_{\theta_{g}}\frac{1}{m}\sum_{i=1}^{m}[\log D(x^{(i)}) + \log (1-D(G(z^{(i)})))]$$

---
### Conditional GAN
<br>
vanilla GAN의 경우 생성되는 이미지를 조절할 수 없다. MNIST dataset을 기준으로 이미지를 생성한다고 할 때, 어떤 숫자를 생성할지 사용자가 조절하기 힘들다. 따라서 Conditional GAN에서는 auxiliary information을 추가하여 생성되는 데이터에 대한 조건을 추가한다. <br> <br>
Loss: $$\min_{G}\max_{D}V(D,G) = \mathbb{E}_{x~p_{data}(x)}[\log (D(x\mid y))] + \mathbb{E}_{z~p_{z}(z)}[\log (1-D(G(z\mid y)))]$$<br><br>
MNIST의 경우 100-dimension의 laten vector z로부터 데이터가 생성되는데 z에 MNIST의 클래스 개수에 해당하는 10-dimension의 vector y를 concate하여 input으로 넣게 된다. 
vector y는 n_class-dimension의 one-hot-vector의 형식이 embedding된 같은 차원의 n_class-dimension vector다.

![GAN1_Image2](https://user-images.githubusercontent.com/48177363/140280245-5df6e893-4fe1-49f6-8bd3-5f2c5e09ffb0.jpg){: width="750"} <br>

---
### Pix2Pix
<br>
Pix2Pix는 CGAN에서 생성하는 이미지의 condition을 이미지로 주는 model이다. Condition 이미지 자체가 Generator의 INPUT으로 들어간다.<br>
x를 condition, y를 Ground Truth, z를 latent라 할 때, Loss는
- $$\mathcal{L}_{cGAN}(G,D)$$: $$ \mathbb{E}_{x,y}[\log D(x,y)] + \mathbb{E}_{x,z}[\log 1-D(x,G(x,z))]$$ <br>
- $$\mathcal{L}_{pix}(G)$$: $$\mathbb{E}_{x,y,z}[\lVert y - D(x,z) \rVert]$$ <br>
- G: $$\mathcal{L}_{cGAN}(1,D(G(z),z)) + \mathcal{L}_{pix}(G(z),y)$$ <br>
- D: $$\mathcal{L}_{cGAN}(1,D(z,y)) + \mathcal{L}_{cGAN}(0,D(G(z),y))$$ <br>
로 나타난다. Pix2Pix에는 <br>
- CNN (UNet) <br>
- PatchGAN의 Discriminator<br>
가 적용되었다. <br>

###### PatchGAN
<br>
PatchGAN은 기존의 GAN이 Discriminator를 속이려는 방향으로만 학습을 진행하다보니 생성된 데이터에 blur가 발생하거나 특정 성격이 강화되는 현상을 해결하기 위한 방법을 제시한다. <br>
PatchGAN의 Discriminator에서는 기존의 FCN을 사용하던 Discriminator와 다르게 CNN을 사용하였다. 이미지의 참/거짓 판단 여부를 여러 패치에서 모두 참이 되도록 학습을 진행한다. D는 Output feature로 NxN feature map을 생성한다. 논문에서 256x256 사이즈의 input image에 대해 output feature map의 각 unit의 receptive field는 70x70 이다. 논문에서는 각 unit에서 receptive field 밖의 영역은 independent 하다고 가정했다. input size에 따라 적절한 receptive field가 다른 hyperparameter다. PatchGAN의 D는 <br>
- Parameter 수의 감소 <br>
- high frequency에 대한 성능 강화 <br>
논문에서 CrossEntorpy를 사용하여 NxN feature map에 대한 Loss를 계산했지만 D에 convnet을 사용한 경우 모두 PatchGAN으로 봐도 된다는 [issue](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/39)가 있다. 따라서 NxN feature의 평균으로 Loss를 계산하는 경우와 1x1 feature를 쓰는 경우에도 PatchGAN이라고 볼 수 있다.


---
### CycleGAN
<br>
기존의 Pix2Pix는 Condition image에 대한 GT가 존재해야하기 때문에 dataset이 unpair한 경우 translation이 불가능하다. CycleGAN에서는 unpaired한 경우에 대한 translation 방법을 제시한다.<br>
CycleGAN은 기본적으로 Unpaired한 각각의 dataset에 대한 translation을 위해 2개의 Generator와 2개의 Discriminator로 구성된다. <br>
![GAN1_Image8](https://user-images.githubusercontent.com/48177363/140329623-25759d98-de33-4887-93a5-cc0e304cacbb.jpg){: width="750"} <br>
우선적으로 CycleGAN의 Loss는 <br>
- $$\mathcal{L}_{GAN}: \mathbb{E}_{y~p_{data}(y)}[\log D_{y}(y)] + \mathbb{E}_{x~p_{data}(x)}[\log D_{y}(G(x))]$$ <br>
- $$\mathcal{L}_{cyc}: \mathbb{E}_{x~p_{data}(x)}[\lVert F(G(x))-x \rVert_{1}] + \mathbb{E}_{y~p_{data}(y)}[\lVert G(F(y))-y \rVert_{1}]$$ <br>
- $$\mathcal{L}_{idt}: \mathbb{E}_{y~p_{data}(y)}[\lVert G(y)-y \rVert_{1}] + \mathbb{E}_{x~p_{data}(x)}[\lVert F(x)-x \rVert_{1}]$$ <br>


---
### StarGAN
<br>
현재까지의 GAN들은 2개 이상의 domain에 대해 다루기에 robust하다. StarGAN은 여러 도메인의 dataset에 생성 모델을 적용하기 위한 모델이다. 기존의 GAN의 경우 4개의 도메인에 대해 변환을 진행할 떼, 12개의 Generator가 필요하다. 따라서 여러 도메인에 대한 통합 모델인 StarGAN이 제안되었다. StarGAN은 하나의 generator로 여러 도메인 간의 translate를 수행한다.<br>

![GAN1_Image3](https://user-images.githubusercontent.com/48177363/140310456-bf251cae-ebbf-4216-89c7-829d61d940db.jpg){: width="750"} <br>

StarGAN은 Cycle GAN과 Condition GAN이 합쳐진 형태다. Input이 translate를 원하는 target domain label과 같이 generator에 Input으로 들어가 fake image를 만들게 된다. CycleGAN과 같이 reconstruction을 위해 fake image가 원래 image의 label을 condition으로 하여 input으로 generator로 다시 들어간다. 2개의 generator를 쓴 CycleGAN과는 다르게 fake image를 만드는데 썼던 generator에 들어가게 된다. <br>
Discriminator는 input으로 받은 이미지에 대해 fake/real을 판단하는 $$D_{src}$$와 domain을 판단하는 $$D_{cls}$$를 output으로 만들어낸다. <br>

![GAN1_Image4](https://user-images.githubusercontent.com/48177363/140313000-fe3b43be-6aa4-48b6-8bc7-c592d0740e03.jpg){: width="750"} <br>

StarGAN의 Loss로는 $$x$$는 input image, $$c, c'$$는 각각 target domain label, orign domain label이라고 할 때,<br>
- $$\mathcal{L}_{adv}: \mathbb{E}_{x}[\log D_{src}(x)] + \mathbb{E}_{x,c}[\log (1-D_{src}(G(x,c)))]$$<br>
- $$\mathcal{L}_{cls}^{r}: \mathbb{E}_{x,c'}[-\log D_{cls}(c'\mid x)]$$<br>
- $$\mathcal{L}_{cls}^{f}: \mathbb{E}_{x,c}[-\log D_{cls}(c'\mid G(x,c'))]$$<br>
- $$\mathcal{L}_{rec}: \mathbb{E}_{x,c,c'}[\lVert x-G(G(x,c),c') \rVert_{1}]$$<br><br>
- $$\mathcal{L}_{G}: \mathcal{L}_{adv} + \lambda_{cls} \mathcal{L}_{cls}^{f} + \lambda_{rec}\mathcal{L}_{rec}$$<br>
- $$\mathcal{L}_{D}: -\mathcal{L}_{adv} + \lambda_{cls}\mathcal{L}_{cls}^{r}$$<br>

으로 나타난다. <br>
G에 대한 훈련은 생성된 이미지에 대한 Loss인 $$\mathcal{L}_{adv}$$와, 생성된 이미지의 label에 대한 Loss인  $$\mathcal{L}_{cls}^{f}$$, 그리고 image collapse를 방지하기 위한 $$\mathcal{L}_{rec}$$으로 구성된다. <br>
D에 대해서는 이미지를 더 잘 구별하기 위한 $$-\mathcal{L}_{adv}$$와 실제 이미지에 대한 label 판단인 $$\mathcal{L}_{cls}^{r}$$로 구성된다.<br>
$$\mathcal{L}_{adv}$$의 경우 Wasserstein GAN의 Loss를 사용하면 성능이 더 향상된다는 논문의 언급이 있다.<br>

###### Network
Generator는 기본적으로 Resblock으로 이루어져있다. Downsampling을 수행하는 Conv 2개와 Residual Block 6개, Upsampling을 수행하는 Deconv 2개로, 총 18개의 convoluation layer가 사용된다. 
image에 대한 target label은 image size만큼 repeat되어, channel dimension에서 concate되어 generator의 input으로 들어간다.<br>

![GAN1_Image5](https://user-images.githubusercontent.com/48177363/140325350-737e4747-b5de-4fca-aad9-1dd1f7c6517c.jpg){: width="750"} <br>

Discriminator는 기본적으로 PatchGAN(ConvNet)으로 구성되어 있다. <br>

![GAN1_Image6](https://user-images.githubusercontent.com/48177363/140326030-80bc2d0f-5b65-45f4-b6ee-b8f7e691ccef.jpg){: width="750"} <br>

###### Mask Vector m
StarGAN은 여러 attribute뿐만 아니라 서로 다른 dataset을 한꺼번에 훈련하는 경우에 대해서도 언급했다. 논문에선 CelebA와 RaFD dataset을 같이 훈련시켰는데 두 dataset의 label 정보는 다르다. CelebA에는 머리색, 나이 등에 대한 labeling이 되어있지만 RaFD dataset에는 다른 attribute에 대한 label만 존재한다. 따라서 위 두 dataset을 같이 훈련시킬 때, 다른 dataset에 대한 훈련에 영향을 끼치지 않기위해 StarGAN에서는 Mask Vector m을 제시한다. target label이 속하는 dataset에 대한 mask를 input으로 추가해, 다른 dataset에 대한 label에 대해서는 훈련이 진행되지 않도록 한다. <br>
![GAN1_Image7](https://user-images.githubusercontent.com/48177363/140328458-87454f46-aaf6-4930-8524-0e888caef46f.jpg){: width="750"} <br>

---
### PGGAN




---



