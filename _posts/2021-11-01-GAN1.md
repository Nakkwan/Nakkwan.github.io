---
title: GAN 1
tags:
  - Deep Learning
  - Paper
  - GAN
---
A brief note on GANs <br>
vanilla GAN, Conditional GAN, Pix2Pix, PatchGAN, StarGAN, PGGAN
<!--more-->

---
### vanilla GAN
<br>
GAN = Generative Adversarial Network <br>
GAN은 진짜 모델과 비슷한 가짜 모델을 만드는 적대적 생성 네트워크로 unsupervised training에 속한다.<br>
latent variable z로부터 가짜 데이터를 생성하는 Generator G와 G로부터 생성한 가짜 데이터와 진짜 데이터를 구별하는 Discriminator D가 존재한다. 
G는 D를 속일 수 있도록 학습되고 D는 진짜 데이터를 판별할 수 있도록 학습되며 G와 D가 경쟁하여 학습된다. <br>

<img src="https://user-images.githubusercontent.com/48177363/140280172-dfe2449f-0e34-4ab5-88f4-b4a47b05ee67.jpg" width=750> <br>

Loss: $$\min_{G}\max_{D}V(D,G) = \mathbb{E}_{x~p_{data}(x)}[\log (D(x))] + \mathbb{E}_{z~p_{z}(z)}[\log (1-D(G(z)))]$$<br>
- G: $$\nabla_{\theta_{g}}\frac{1}{m}\sum_{i=1}^{m}\log (1-D(G(z^{(i)})))$$ <br>
- D: $$\nabla_{\theta_{g}}\frac{1}{m}\sum_{i=1}^{m}[\log D(x^{(i)}) + \log (1-D(G(z^{(i)})))]$$

---
### Conditional GAN
<br>
vanilla GAN의 경우 생성되는 이미지를 조절할 수 없다. MNIST dataset을 기준으로 이미지를 생성한다고 할 때, 어떤 숫자를 생성할지 사용자가 조절하기 힘들다. 따라서 Conditional GAN에서는 auxiliary information을 추가하여 생성되는 데이터에 대한 조건을 추가한다. <br>
Loss: $$\min_{G}\max_{D}V(D,G) = \mathbb{E}_{x~p_{data}(x)}[\log (D(x\mid y))] + \mathbb{E}_{z~p_{z}(z)}[\log (1-D(G(z\mid y)))]$$<br>
MNIST의 경우 100-dimension의 laten vector z로부터 데이터가 생성되는데 z에 MNIST의 클래스 개수에 해당하는 10-dimension의 vector y를 concate하여 input으로 넣게 된다. 
vector y는 n_class-dimension의 one-hot-vector의 형식이 embedding된 같은 차원의 n_class-dimension vector다.

<img src="https://user-images.githubusercontent.com/48177363/140280245-5df6e893-4fe1-49f6-8bd3-5f2c5e09ffb0.jpg" width=750> <br>

---
### Pix2Pix
<br>
Pix2Pix는 CGAN에서 생성하는 이미지의 condition을 이미지로 주는 model이다. Condition 이미지 자체가 Generator의 INPUT으로 들어간다.<br>
x를 condition, y를 Ground Truth, z를 latent라 할 때, Loss는
- $$\mathcal{L}_{cGAN}(G,D)$$: $$ \mathbb{E}_{x,y}[\log D(x,y)] + \mathbb{E}_{x,z}[\log 1-D(x,G(x,z))]$$ <br>
- $$\mathcal{L}_{pix}(G)$$: $$\mathbb{E}_{x,y,z}[\lVert y - D(x,z) \rVert]$$ <br>
- G: $$\mathcal{L}_{cGAN}(1,D(G(z),z))) + \mathcal{L}_{pix}(G(z),y)$$ <br>
- D: $$\mathcal{L}_{cGAN}(1,D(z,y))) + \mathcal{L}_{cGAN}(0,D(G(z),y))) <br>
로 나타난다. <br>
Pix2Pix에는 <br>
- CNN (UNet) <br>
- PatchGAN의 Discriminator<br>
가 적용되었다. <br>

##### PatchGAN
<br>
PatchGAN은 기존의 GAN이 Discriminator를 속이려는 방향으로만 학습을 진행하다보니 생성된 데이터에 blur가 발생하거나 특정 성격이 강화되는 현상을 해결하기 위한 방법을 제시한다. <br>
PatchGAN의 Discriminator에서는 기존의 FCN을 사용하던 Discriminator와 다르게 CNN을 사용하였다. 이미지의 참/거짓 판단 여부를 여러 패치에서 모두 참이 되도록 학습을 진행한다. D는 Output feature로 NxN feature map을 생성한다. 논문에서 256x256 사이즈의 input image에 대해 output feature map의 각 unit의 receptive field는 70x70 이다. 논문에서는 각 unit에서 receptive field 밖의 영역은 independent 하다고 가정했다. input size에 따라 적절한 receptive field가 다른 hyperparameter다. PatchGAN의 D는 <br>
- Parameter 수의 감소 <br>
- high frequency에 대한 성능 강화 <br>
논문에서 CrossEntorpy를 사용하여 NxN feature map에 대한 Loss를 계산했지만 D에 convnet을 사용한 경우 모두 PatchGAN으로 봐도 된다는 [issue](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/39)가 있다. 따라서 NxN feature의 평균으로 Loss를 계산하는 경우와 1x1 feature를 쓰는 경우에도 PatchGAN이라고 볼 수 있다.

---
### StarGAN
<br>


